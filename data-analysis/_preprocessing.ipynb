{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from datetime import datetime\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "tqdm_notebook.pandas()\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "PROJECT_ROOT = '..'\n",
    "CSV_FOLDER = 'csv'\n",
    "\n",
    "%run _utils.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "issues = pd.read_csv(f'{PROJECT_ROOT}/{CSV_FOLDER}/greenkeeper_issues.csv')\n",
    "comments = pd.read_csv(f'{PROJECT_ROOT}/{CSV_FOLDER}/greenkeeper_comments.csv')\n",
    "events = pd.read_csv(f'{PROJECT_ROOT}/{CSV_FOLDER}/greenkeeper_events.csv')\n",
    "commits = pd.read_csv(f'{PROJECT_ROOT}/{CSV_FOLDER}/greenkeeper_commits.csv')\n",
    "package_names = pd.read_csv(f'{PROJECT_ROOT}/{CSV_FOLDER}/greenkeeper_package_names.csv')\n",
    "library_versions = pd.read_csv(f'{PROJECT_ROOT}/{CSV_FOLDER}/breaking_library_versions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Commits</h3>\n",
    "<p>Add <b>commit_issue_id</b> to commits</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_get_issue_id_for_commit(commit):\n",
    "    return get_issue_id_for_commit(events, issues, commit)\n",
    "\n",
    "commits['commit_issue_id'] = commits.progress_apply(local_get_issue_id_for_commit, axis=1)\n",
    "commits.to_csv(f'{PROJECT_ROOT}/{CSV_FOLDER}/aug_greenkeeper_commits.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Issues</h3>\n",
    "<p>Add <b>update_type</b> to issues</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_get_update_type(row):\n",
    "    actual_version = row['issue_dependency_actual_version']\n",
    "    next_version = row['issue_dependency_next_version']\n",
    "    return get_update_type_v2(actual_version, next_version)\n",
    "\n",
    "issues['update_type'] = \\\n",
    "    issues.progress_apply(local_get_update_type, axis=1)\n",
    "issues.to_csv(f'{PROJECT_ROOT}/{CSV_FOLDER}/aug_greenkeeper_issues.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_repo_names = pd.Series(issues['repo_url'].unique()).apply(lambda url: url.split('https://api.github.com/repos/')[1]).to_frame(name='repo')\n",
    "raw_repo_names.to_csv(f'{PROJECT_ROOT}/{CSV_FOLDER}/raw_repo_names.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Package dependencies</h3>\n",
    "<p>Parse dev and dev_dep strings to json and then flatten the DTOs for the dataframe</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def str_to_dict(s):\n",
    "    if pd.isna(s):\n",
    "        return dict()\n",
    "    return json.loads(s.replace(\"'\", '\"')) if ~pd.isna(s) else dict()\n",
    "\n",
    "# Parse dev and dev_dep strings to json\n",
    "deps_dtos = list()\n",
    "for index, row in tqdm_notebook(package_names.iterrows()):\n",
    "    deps_dtos.append({\n",
    "        'package_name': row['package_name'],\n",
    "        'deps': str_to_dict(row['package_dependencies']),\n",
    "        'dev_deps': str_to_dict(row['package_dev_dependencies']),\n",
    "    })\n",
    "\n",
    "# Flatten dtos for df\n",
    "DEP = 'Dependency'\n",
    "DEV_DEP = 'Dev Dependency'\n",
    "packages = list()\n",
    "deps_names = list()\n",
    "deps_versions = list()\n",
    "deps_types =  list()\n",
    "for deps_dto in tqdm_notebook(deps_dtos):\n",
    "    package = deps_dto['package_name']\n",
    "    for dep_name, dep_version in deps_dto['deps'].items():\n",
    "        packages.append(package)\n",
    "        deps_names.append(dep_name)\n",
    "        deps_versions.append(dep_version)\n",
    "        deps_types.append(DEP)\n",
    "    for dep_name, dep_version in deps_dto['dev_deps'].items():\n",
    "        packages.append(package)\n",
    "        deps_names.append(dep_name)\n",
    "        deps_versions.append(dep_version)\n",
    "        deps_types.append(DEV_DEP)\n",
    "        \n",
    "dependencies_df = pd.DataFrame({\n",
    "    'package': packages,\n",
    "    'deps_name': deps_names,\n",
    "    'deps_version': deps_versions,\n",
    "    'deps_type': deps_types,\n",
    "})\n",
    "dependencies_df.to_csv(f'{PROJECT_ROOT}/{CSV_FOLDER}/package_dependencies.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Provider-to-clients</h3>\n",
    "<p><i>Invert</i> the dependencies df to get the clients that depend on every provider</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deps_groups = dependencies_df.groupby(by=['deps_name'])\n",
    "provider_packages_list = list()\n",
    "clients_list = list()\n",
    "for name, group in tqdm_notebook(deps_groups):\n",
    "    provider_packages_list.extend([name for i in range(len(group))])\n",
    "    clients_list.extend(list(group.apply(lambda row: row['package'], axis=1)))\n",
    "\n",
    "provider_to_clients = pd.DataFrame({\n",
    "    'provider': provider_packages_list,\n",
    "    'client': clients_list,\n",
    "})\n",
    "\n",
    "provider_to_clients.to_csv(f'{PROJECT_ROOT}/{CSV_FOLDER}/provider_to_clients.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# library_versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library_versions[\"version_published_at\"] = library_versions[\"version_published_at\"].astype(\"datetime64\")\n",
    "library_versions = library_versions.dropna(subset=['package_name'])\n",
    "library_versions = library_versions.sort_values(['package_name', 'version_published_at'])\n",
    "\n",
    "all_release_types = list()\n",
    "\n",
    "result = {\n",
    "    'package_name': list(),\n",
    "    'total_time_diff': list(),\n",
    "    'avg_time_between_releases': list(),\n",
    "    'first_release_date': list(),\n",
    "    'last_release_date': list(),\n",
    "    'total_releases': list(),\n",
    "}\n",
    "\n",
    "grouped_package_releases = library_versions.groupby(by='package_name')\n",
    "\n",
    "# Loop over every release record for a specific library.\n",
    "# Keep adding the time between each release to total_time_diff\n",
    "# After loop, calculate avg time between releases\n",
    "# Also keep track of each release type (MAJOR, MINOR< PATCH) and\n",
    "# save it in all_release_types to be added as a columnn to library_versions df\n",
    "def calculate_release_data_for_library(library, versions_df):\n",
    "    prev_release_date = None\n",
    "    curr_release_date = None\n",
    "    prev_release_number = None\n",
    "    curr_release_number = None\n",
    "    first_release_date = None\n",
    "    releases_count = 0\n",
    "    total_time_diff = pd.Timedelta(seconds=0)\n",
    "    for row_index, row in group.iterrows():\n",
    "        prev_release_date = curr_release_date\n",
    "        prev_release_number = curr_release_number\n",
    "        curr_release_date = row['version_published_at']\n",
    "        curr_release_number = row['version']\n",
    "        releases_count += 1\n",
    "        if prev_release_date is None:\n",
    "            first_release_date = curr_release_date\n",
    "            all_release_types.append(NA_RELEASE_TYPE)\n",
    "            continue\n",
    "        local_time_diff = (curr_release_date - prev_release_date)\n",
    "        total_time_diff += local_time_diff\n",
    "        all_release_types.append(get_update_type_v2(prev_release_number, curr_release_number))\n",
    "    avg = total_time_diff / releases_count\n",
    "    result['package_name'].append(package_name)\n",
    "    result['total_time_diff'].append(total_time_diff)\n",
    "    result['avg_time_between_releases'].append(avg)\n",
    "    result['first_release_date'].append(first_release_date)\n",
    "    result['last_release_date'].append(curr_release_date)\n",
    "    result['total_releases'].append(releases_count)\n",
    "\n",
    "\n",
    "for package_name, group in tqdm_notebook(grouped_package_releases):\n",
    "    calculate_release_data_for_library(package_name, group)\n",
    "library_versions['version_release_type'] = all_release_types\n",
    "\n",
    "library_releases = pd.DataFrame(result)\n",
    "library_releases['broken_builds_caused'] = \\\n",
    "    library_releases.progress_apply(\n",
    "        lambda row: len(issues[issues['issue_dependency_name'] == row['package_name']]), axis=1)\n",
    "\n",
    "def get_count_of_issues(library_version, df):\n",
    "    version_issues = df[df['issue_dependency_next_version'] == library_version]\n",
    "    return len(version_issues)\n",
    "\n",
    "broken_clients_count = list()\n",
    "grouped = library_versions.groupby(by=['package_name'])\n",
    "for package, df in tqdm_notebook(grouped):\n",
    "    issues_for_package = \\\n",
    "        issues[issues['issue_dependency_name'] == package]\n",
    "    for idx, row in df.iterrows():\n",
    "        breaks_count = get_count_of_issues(row['version'], issues_for_package)\n",
    "        broken_clients_count.append(breaks_count)\n",
    "                \n",
    "library_versions['broken_clients_count'] = broken_clients_count\n",
    "\n",
    "\n",
    "grouped = library_versions.groupby(by=['package_name'])\n",
    "result = list()\n",
    "last_idx = 0\n",
    "for package_name, group in tqdm_notebook(grouped):\n",
    "    last_idx += len(group)\n",
    "    for idx, lv_row in group.iterrows():\n",
    "        next_idx = idx + 1\n",
    "#         print(f'idx={idx} next_idx={next_idx} len={len(group)}')\n",
    "        if next_idx >= last_idx:\n",
    "            result.append(pd.NA)\n",
    "        else:\n",
    "            result.append(group.loc[next_idx]['version_published_at'] - lv_row['version_published_at'])\n",
    "library_versions['time_until_next_release'] = result\n",
    "\n",
    "\n",
    "library_versions.to_csv(f'{PROJECT_ROOT}/{CSV_FOLDER}/aug_breaking_library_versions.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>library_releases</h3>\n",
    "<p>Calculate <b>avg_time_between_releases_seconds</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library_releases['avg_time_between_releases_seconds'] = \\\n",
    "    (library_releases['avg_time_between_releases'].dt.days * 24 * 60 * 60) + \\\n",
    "    (library_releases['avg_time_between_releases'].dt.seconds)\n",
    "library_releases.to_csv(f'{PROJECT_ROOT}/{CSV_FOLDER}/breaking_library_releases.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# packages_release_and_breaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = library_versions.groupby(by=['package_name'])\n",
    "\n",
    "result = {\n",
    "    'package': list(),\n",
    "    'total_releases': list(),\n",
    "    'total_breaks': list(),\n",
    "    'major_releases': list(),\n",
    "    'major_breaks': list(),\n",
    "    'minor_releases': list(),\n",
    "    'minor_breaks': list(),\n",
    "    'patch_releases': list(),\n",
    "    'patch_breaks': list()\n",
    "}\n",
    "\n",
    "def release_broke_a_client(package, version, df):\n",
    "    result = df.loc[\n",
    "        (df['issue_dependency_next_version'] == version)\n",
    "    ]\n",
    "    return not result.empty\n",
    "\n",
    "for package, df in tqdm_notebook(grouped):\n",
    "    patch_count = 0\n",
    "    patch_breaks_count = 0\n",
    "    minor_count = 0\n",
    "    minor_breaks_count = 0\n",
    "    major_count = 0\n",
    "    major_breaks_count = 0\n",
    "    issues_for_package = \\\n",
    "        issues_with_update_type_count[issues_with_update_type_count['issue_dependency_name'] == package]\n",
    "    for idx, row in df.iterrows():\n",
    "        if row['version_release_type'] == PATCH:\n",
    "            patch_count += 1\n",
    "            if release_broke_a_client(package, row['version'], issues_for_package):\n",
    "                patch_breaks_count += 1\n",
    "        elif row['version_release_type'] == MINOR:\n",
    "            minor_count += 1\n",
    "            if release_broke_a_client(package, row['version'], issues_for_package):\n",
    "                minor_breaks_count += 1\n",
    "        elif row['version_release_type'] == MAJOR:\n",
    "            major_count += 1\n",
    "            if release_broke_a_client(package, row['version'], issues_for_package):\n",
    "                major_breaks_count += 1\n",
    "    result['package'].append(package)\n",
    "    result['total_releases'].append(major_count + minor_count + patch_count)\n",
    "    result['total_breaks'].append(major_breaks_count + minor_breaks_count + patch_breaks_count)\n",
    "    result['major_releases'].append(major_count)\n",
    "    result['major_breaks'].append(major_breaks_count)\n",
    "    result['minor_releases'].append(minor_count)\n",
    "    result['minor_breaks'].append(minor_breaks_count)\n",
    "    result['patch_releases'].append(patch_count)\n",
    "    result['patch_breaks'].append(patch_breaks_count)\n",
    "        \n",
    "packages_release_and_breaks_df = pd.DataFrame(result)\n",
    "\n",
    "packages_release_and_breaks_df['total_ratio'] = \\\n",
    "    packages_release_and_breaks_df['total_breaks'] / packages_release_and_breaks_df['total_releases']\n",
    "packages_release_and_breaks_df['major_ratio'] = \\\n",
    "    packages_release_and_breaks_df['major_breaks'] / packages_release_and_breaks_df['major_releases']\n",
    "packages_release_and_breaks_df['minor_ratio'] = \\\n",
    "    packages_release_and_breaks_df['minor_breaks'] / packages_release_and_breaks_df['minor_releases']\n",
    "packages_release_and_breaks_df['patch_ratio'] = \\\n",
    "    packages_release_and_breaks_df['patch_breaks'] / packages_release_and_breaks_df['patch_releases']\n",
    "\n",
    "packages_release_and_breaks_df.to_csv(f'{PROJECT_ROOT}/{CSV_FOLDER}/releases_and_breaks_counts_by_package.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
